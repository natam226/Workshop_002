{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ce227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import html\n",
    "import logging\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf2ca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total artistas √∫nicos: 31437\n",
      "üöÄ Consultando Wikidata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîé Batches SPARQL: 31440it [10:59, 47.69it/s]                           \n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 1. CARGAR Y LIMPIAR CSV\n",
    "# =======================\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def limpiar_nombre(nombre):\n",
    "    if pd.isna(nombre) or not nombre.strip():\n",
    "        return None\n",
    "    nombre = nombre.replace(\"\\\\\", \"\").replace('\"', '').replace(\"'\", \"\")\n",
    "    nombre = nombre.replace(\",\", \"\").replace(\"/\", \" \").replace(\"&\", \"and\")\n",
    "    return nombre.strip()\n",
    "\n",
    "df = pd.read_csv(\"../data/artists.csv\", header=None, names=[\"raw\"])\n",
    "nombres_limpios = [limpiar_nombre(nombre) for nombre in df[\"raw\"]]\n",
    "artistas_unicos = sorted(set([nombre for nombre in nombres_limpios if nombre]))\n",
    "\n",
    "print(f\"‚úÖ Total artistas √∫nicos: {len(artistas_unicos)}\")\n",
    "\n",
    "# =======================\n",
    "# 2. CONSULTA SPARQL SIN \"death\"\n",
    "# =======================\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/sparql-results+json\",\n",
    "    \"User-Agent\": \"Workshop/1.0 (tucorreo@example.com)\"  # <-- C√°mbialo por el tuyo\n",
    "}\n",
    "\n",
    "def construir_query_sparql(artistas):\n",
    "    values = \"\\n\".join([f'\"{nombre}\"@en' for nombre in artistas])\n",
    "    query = f\"\"\"\n",
    "    SELECT ?artistLabel ?countryLabel ?awardLabel ?genderLabel (COUNT(?album) AS ?albumCount) WHERE {{\n",
    "      VALUES ?name {{ {values} }}\n",
    "      ?artist rdfs:label ?name.\n",
    "      OPTIONAL {{ ?artist wdt:P166 ?award. }}\n",
    "      OPTIONAL {{ ?artist wdt:P27 ?country. }}\n",
    "      OPTIONAL {{ ?artist wdt:P21 ?gender. }}\n",
    "\n",
    "      OPTIONAL {{\n",
    "        ?album wdt:P31 wd:Q482994.\n",
    "        ?album wdt:P175 ?artist.\n",
    "      }}\n",
    "\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    GROUP BY ?artistLabel ?countryLabel ?awardLabel ?genderLabel\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "def obtener_datos_wikidata(artistas_batch):\n",
    "    query = construir_query_sparql(artistas_batch)\n",
    "    try:\n",
    "        response = requests.post(WIKIDATA_ENDPOINT, data={\"query\": query}, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"‚ùå Error en SPARQL:\", e)\n",
    "        return None\n",
    "\n",
    "# =======================\n",
    "# 3. CONSULTA ROBUSTA\n",
    "# =======================\n",
    "print(\"üöÄ Consultando Wikidata...\")\n",
    "\n",
    "MAX_QUERY_SIZE = 60000\n",
    "results = []\n",
    "i = 0\n",
    "\n",
    "with tqdm(total=len(artistas_unicos), desc=\"üîé Batches SPARQL\") as pbar:\n",
    "    while i < len(artistas_unicos):\n",
    "        batch_size = 80\n",
    "        batch_success = False\n",
    "\n",
    "        while batch_size > 0 and not batch_success:\n",
    "            batch = artistas_unicos[i:i+batch_size]\n",
    "            query = construir_query_sparql(batch)\n",
    "            if len(query.encode(\"utf-8\")) > MAX_QUERY_SIZE:\n",
    "                batch_size -= 5\n",
    "                continue\n",
    "\n",
    "            data = obtener_datos_wikidata(batch)\n",
    "            if data:\n",
    "                for row in data[\"results\"][\"bindings\"]:\n",
    "                    results.append({\n",
    "                        \"artist\": row.get(\"artistLabel\", {}).get(\"value\", \"\"),\n",
    "                        \"country\": row.get(\"countryLabel\", {}).get(\"value\", \"\"),\n",
    "                        \"award\": row.get(\"awardLabel\", {}).get(\"value\", \"No awards\"),\n",
    "                        \"gender\": row.get(\"genderLabel\", {}).get(\"value\", \"Unknown\"),\n",
    "                        \"album_count\": row.get(\"albumCount\", {}).get(\"value\", \"0\")\n",
    "                    })\n",
    "                batch_success = True\n",
    "                i += batch_size\n",
    "                pbar.update(batch_size)\n",
    "                time.sleep(0.8)\n",
    "            else:\n",
    "                batch_size = batch_size // 2\n",
    "\n",
    "        if not batch_success:\n",
    "            print(f\"‚ö†Ô∏è  Saltando artista en √≠ndice {i}: {artistas_unicos[i]}\")\n",
    "            i += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "# =======================\n",
    "# 4. GUARDAR RESULTADOS\n",
    "# =======================\n",
    "columnas_ordenadas = [\"artist\", \"country\", \"award\", \"gender\", \"album_count\"]\n",
    "df_result = pd.DataFrame(results, columns=columnas_ordenadas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36eacac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo 'api_data_part1.csv' creado correctamente.\n",
      "‚úÖ Archivo 'api_data_part2.csv' creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Calcular el punto de divisi√≥n (por la mitad en este caso)\n",
    "halfway = len(df_result) // 2\n",
    "\n",
    "# Guardar la primera parte del DataFrame\n",
    "df_result.iloc[:halfway].to_csv(\"../data/api_data_part1.csv\", index=False)\n",
    "print(\"‚úÖ Archivo 'api_data_part1.csv' creado correctamente.\")\n",
    "\n",
    "# Guardar la segunda parte del DataFrame\n",
    "df_result.iloc[halfway:].to_csv(\"../data/api_data_part2.csv\", index=False)\n",
    "print(\"‚úÖ Archivo 'api_data_part2.csv' creado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
